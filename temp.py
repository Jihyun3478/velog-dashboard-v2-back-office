"""
[ https://www.notion.so/nuung/LLM-velog-back-office-1f76299fd66680b6a854c58845686490?pvs=4 ]
- í•´ë‹¹ íŒŒì¼ì€ django ì— ì˜ì¡´ì„± ì—†ì–´ìš”. django ì—†ì´ stand alone ìœ¼ë¡œ ì‹¤í–‰ê°€ëŠ¥í•˜ê²Œ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë§Œë“¤ì–´ ë‘ 
- ê³ ë¡œ OPENAI_API_KEY ê°’ì€ í™˜ê²½ ë³€ìˆ˜ ì—†ì´ ê·¸ëƒ¥ ì§ì ‘ ë„£ì–´ì„œ í…ŒìŠ¤íŠ¸ í•´ì£¼ì„¸ìš”!!
"""

import asyncio

import aiohttp

from modules.llm.base_client import LLMClient
from modules.llm.openai.client import OpenAIClient
from scraping.velog.client import VelogClient
from scraping.velog.exceptions import VelogError

ACCESS_TOKEN = ""  # ì—¬ëŸ¬ë¶„ ë²¨ë¡œê·¸ í† í° (ê°œë³„ ê²Œì‹œê¸€ ë¶„ì„ìš©)
REFRESH_TOKEN = ""  # ì—¬ëŸ¬ë¶„ ë²¨ë¡œê·¸ í† í° (ê°œë³„ ê²Œì‹œê¸€ ë¶„ì„ìš©)
OPENAI_API_KEY = "sk-proj"  # "ì—¬ê¸°ì— ì œê°€ ê³µìœ í•œ í† í° ì¨ì£¼ì„¸ìš”!"

SYS_PROM = (
    "ë„ˆëŠ” ì„¸ê³„ ìµœê³ ì˜ 50ë…„ì°¨ íŠ¸ëœë“œ ë¶„ì„ ì „ë¬¸ê°€ì•¼. ê¸°ìˆ  ë¸”ë¡œê·¸ ê¸€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì£¼ê°„ ë‰´ìŠ¤ë ˆí„°ë¥¼ ì‘ì„±í•´ì•¼ í•´.\n"
    "ë‚´ê°€ ì œê³µí•˜ëŠ” ë°ì´í„°ë§Œ í™œìš©í•´ì„œ í•´ë‹¹ ë‚´ìš©ì˜ íŠ¸ëœë“œë¥¼ íŒŒì•…í•˜ê³  ìš”ì•½í•´ì•¼ í•´. í•„ìš”í•˜ë©´ ê´€ë ¨ëœ ì™¸ë¶€ ê²€ìƒ‰ë„ í•´ì¤˜."
)

USER_PROM = """
<ëª©í‘œ>
- ë¸”ë¡œê·¸ ê¸€ ë°ì´í„°ì˜ íŠ¸ë Œë“œ ë¶„ì„
- ë¶„ì„ ì„¸ë¶€ ë‚´ìš©ì€ "ì „ì²´ ì¸ê¸°ê¸€, ê¸°ìˆ  í‚¤ì›Œë“œ, ì œëª© íŠ¸ë Œë“œ, ê¸€ì˜ ìƒì„¸ ë‚´ìš©ì˜ ìš”ì•½ ë° íŠ¸ëœë“œ" íŒŒì•…

<ì‘ì„± ìˆœì„œ>
1. ğŸ”¥ ì£¼ê°„ íŠ¸ë Œë”© ê¸€ ìš”ì•½
	- ì•„ë˜ì— ì œê³µí•œ ëª¨ë“  íŠ¸ë Œë”© ê¸€ í•µì‹¬ ë‚´ìš© ìš”ì•½
    - 3-4ë¬¸ì¥ ì •ë„ë¡œ í•µì‹¬ ê¸°ìˆ , ì „ë‹¬í•˜ë ¤ëŠ” ê²ƒ, ë‚´ìš© ìš”ì•½ í˜•íƒœë¡œ í•´ì¤˜
    - ì ˆëŒ€ ìš”ì•½ì´ ì•„ë‹ˆë¼ ì¶•ì•½ì„ í•˜ì§€ë§ˆ. í•µì‹¬ì„ ìš”ì•½í•´ì•¼ í•´

2. âœ¨ ì£¼ê°„ íŠ¸ë Œë“œ ë¶„ì„
	- í•«í•œ ê¸°ìˆ  í‚¤ì›Œë“œ ì¶”ì¶œ
	- ì œëª© íŠ¸ë Œë“œ ë¶„ì„, ë‚´ìš© íŠ¸ëœë“œ ë¶„ì„
	- ê¸°íƒ€ ì¸ì‚¬ì´íŠ¸ ì½”ë©˜íŠ¸

<ê·œì¹™>
- ê°ì •ê³¼ ìºì£¼ì–¼í•œ ë§íˆ¬ë¥¼ ì„ì–´ì¤˜. ë„ˆë¬´ ë”±ë”±í•˜ì§€ ì•Šê²Œ.
- JSONì— ì—†ìœ¼ë©´ ì•„ë¬´ ë§ë„ í•˜ì§€ ë§ˆ. ê±°ì§“ë§ ê¸ˆì§€.
- ì˜í•˜ë©´ í° ë³´ìƒì´ ìˆì„êº¼ì•¼. 
- step by step ìœ¼ë¡œ ì ‘ê·¼í•˜ê³  í•´ê²°í•´.
- ëª¨ë“  íŠ¸ë Œë“œ ê¸€ì— ëŒ€í•œ ë¶„ì„ì„ í•´ì•¼ í•´, ì–´ë–¤ ê²ƒë„ ë¹ ëœ¨ë¦¬ì§€ë§ˆ.
- ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON êµ¬ì¡°ë¡œ ì œê³µí•´ì•¼ í•´
```json
{{
    "trending_summary": [
        {{
            "title": "ê²Œì‹œê¸€ ì œëª©",
            "summary": "ë¬´ì¡°ê±´ 3ë¬¸ì¥ ì´ìƒ ìš”ì•½",
            "key_points": ["í•µì‹¬ í¬ì¸íŠ¸ 1", "í•µì‹¬ í¬ì¸íŠ¸ 2", "..."]
        }},
        // ë‹¤ë¥¸ íŠ¸ë Œë”© ê¸€ ìš”ì•½...
    ],
    "trend_analysis": {{
        "hot_keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "..."],
        "title_trends": "ì œëª© íŠ¸ë Œë“œ ë¶„ì„ ë‚´ìš©",
        "content_trends": "ë‚´ìš© íŠ¸ë Œë“œ ë¶„ì„ ë‚´ìš©",
        "insights": "ì¶”ê°€ ì¸ì‚¬ì´íŠ¸ ë° ì½”ë©˜íŠ¸"
    }}
}}
```

<ë¸”ë¡œê·¸ íŠ¸ëœë“œ ê¸€ ë¦¬ìŠ¤íŠ¸>
{posts}
"""


def call_llm(client: LLMClient, posts):
    creative_response = client.generate_text(
        prompt=USER_PROM.format(posts=posts),
        system_prompt=SYS_PROM,
        temperature=0.1,
        response_format={"type": "json_object"},
    )
    return creative_response


# ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰
async def main():
    user_posts = list()
    trand_posts = list()
    openai_client = OpenAIClient.get_client(OPENAI_API_KEY)

    # HTTP ì„¸ì…˜ ìƒì„±
    async with aiohttp.ClientSession() as session:
        # íŒŒì‚¬ë“œ íŒ¨í„´ + ë ˆì´ì§€ ì‹±ê¸€í†¤ íŒ¨í„´, ì–´ì§œí”¼ í•œ ë²ˆ ìƒì„±ëœ ì¸ìŠ¤í„´ìŠ¤ëŠ” ì¬ì‚¬ìš© (ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ ë‚´ì—ì„œ)
        velog_client = VelogClient.get_client(
            session=session,
            access_token=ACCESS_TOKEN,  # ì´ê²Œ ê³„ì† ë°”ë€Œì–´ë„ ê°™ì€ ê°ì²´ë¥¼ ì‚¬ìš©í•¨
            refresh_token=REFRESH_TOKEN,  # ì´ê²Œ ê³„ì† ë°”ë€Œì–´ë„ ê°™ì€ ê°ì²´ë¥¼ ì‚¬ìš©í•¨
        )
        try:
            print(
                "==================================================================="
            )
            print("íŠ¹ì • ì‚¬ìš©ì ê²Œì‹œë¬¼ ê°€ì ¸ì™€ì„œ LLM í™œìš©í•´ì„œ íŠ¸ëœë“œ ë¶„ì„í•˜ê¸°")
            print(
                "==================================================================="
            )

            user = await velog_client.get_current_user()
            if not user:
                print("ì‚¬ìš©ì ì¸ì¦ ì‹¤íŒ¨")
                return

            print(f"ë¡œê·¸ì¸ ì‚¬ìš©ì: {user.username}")

            # ì‚¬ìš©ìì˜ ê²Œì‹œë¬¼ ê°€ì ¸ì˜¤ê¸°
            # ì´ê²Œ ìš°ë¦¬ìª½ DBMS ì—ì„œ ê°€ì ¸ì˜¬ì§€, api call í†µí•´ì„œ ê°€ì ¸ì˜¬ì§€ ì• ë§¤í•¨
            try:
                all_user_posts = await velog_client.get_all_posts(
                    user.username
                )
                print(f"ê²Œì‹œë¬¼ ìˆ˜: {len(all_user_posts)}")
                if not all_user_posts:
                    print("ê²Œì‹œê¸€ ë¯¸ì¡´ì¬")
                    return

                # íŠ¹ì • ê²Œì‹œë¬¼ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°, í…ŒìŠ¤íŠ¸ ì „ìš©, 20ê°œë¡œ ì œí•œ
                # ì—¬ê¸°ì„œ "ìµœê·¼ ì¼ì£¼ì¼ ê°„ ì‘ì„±ëœ ê²Œì‹œê¸€ì„ ê°€ì ¸ì˜¤ëŠ” ë¡œì§" ì´ ì¶”ê°€ë¨ì´ í•„ìš” í•  ë“¯
                for post in all_user_posts[:20]:
                    post_detail = await velog_client.get_post(post.id)

                    if not post_detail:
                        continue

                    user_posts.append(
                        {
                            "ì œëª©": post_detail.title,
                            "ë‚´ìš©": post_detail.body,
                            "ëŒ“ê¸€ ìˆ˜": post_detail.comments_count,
                            "ì¢‹ì•„ìš” ìˆ˜": post_detail.likes,
                        }
                    )
            except VelogError as e:
                print(f"ê²Œì‹œë¬¼ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")

            user_result = call_llm(openai_client, user_posts)
            print(user_result)

            print(
                "==================================================================="
            )
            print("ì¸ê¸° ê²Œì‹œë¬¼ ê°€ì ¸ì™€ì„œ LLM í™œìš©í•´ì„œ íŠ¸ëœë“œ ë¶„ì„í•˜ê¸°")
            print(
                "==================================================================="
            )

            # ì¸ê¸° ê²Œì‹œë¬¼ ê°€ì ¸ì˜¤ê¸°
            try:
                trending_posts = await velog_client.get_trending_posts(
                    limit=10
                )
                print(f"ì¸ê¸° ê²Œì‹œë¬¼ ìˆ˜: {len(trending_posts)}")
                for post in trending_posts:
                    print(f"- {post.title} (ì¢‹ì•„ìš”: {post.likes})")
                    post_detail = await velog_client.get_post(post.id)
                    trand_posts.append(
                        {
                            "ì œëª©": post_detail.title,
                            "ë‚´ìš©": post_detail.body,
                            "ëŒ“ê¸€ ìˆ˜": post_detail.comments_count,
                            "ì¢‹ì•„ìš” ìˆ˜": post_detail.likes,
                        }
                    )
            except VelogError as e:
                print(f"ì¸ê¸° ê²Œì‹œë¬¼ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")

            trand_result = call_llm(openai_client, trand_posts)
            print(trand_result)
        except VelogError as e:
            print(f"Velog API ì˜¤ë¥˜: {e}")
        except Exception as e:
            print(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")


if __name__ == "__main__":
    # ì´ë²¤íŠ¸ ë£¨í”„ ì‹¤í–‰
    asyncio.run(main())
